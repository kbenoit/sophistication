---
output:
  md_document:
    variant: markdown_github
---

<!--
[![CRAN Version](http://www.r-pkg.org/badges/version/sophistication)](http://cran.r-project.org/package=sophistication)
![Downloads](http://cranlogs.r-pkg.org/badges/sophistication)
[![Travis-CI Build Status](https://travis-ci.org/kbenoit/sophistication.svg?branch=master)](https://travis-ci.org/kbenoit/sophistication)
[![codecov.io](https://codecov.io/github/kbenoit/sophistication/coverage.svg?branch=master)][1]
-->

## Code for use in measuring the sophistication of political text

"Measuring and Explaining Political Sophistication Through Textual Complexity" by Kenneth Benoit, Kevin Munger, and Arthur Spirling.  This package is built on [**quanteda**](https://github.com/kbenoit/quanteda), whose namespace it imports.

### How to install

Two methods:

1.  Install using **devtools** directly from GitHub, you will need to generate a personal access token (PAT) in https://github.com/settings/tokens and supply it as below: (you should, preferably, use your own!)  
    ```{r, eval = FALSE}
    devtools::install_github("kbenoit/sophistication", subdir = "R_package",
                             auth_token = "309171976db5586eab402a922604229cd5190c81")
    ```
                              
2.  Pull the repo into your project, and choose "**Build & Reload**" from the **Build** tab of the Build pane in RStudio.


### Included Data

new name | original name | description
--------------| -------- | ------- 
`data_corpus_fifthgrade` | `fifthCorpus` | Fifth-grade reading texts
`data_corpus_crimson` | `crimsonCorpus` |  Editorials from the Harvard *Crimson*
`data_corpus_partybroadcast` | `partybcastCorpus` |  UK political party broadcasts
`data_corpus_presdebates` | `presDebateCorpus` | US presidential debates 2016
`data_corpus_SOTU` | `SOTUCorpus` | US State of the Union corpus



### How to use

```{r}
require(sophistication)

# make the snipepts of one sentence, between 100-350 chars in length
snippetData <- snippets_make(data_corpus_SOTU, nsentence = 1, minchar = 150, maxchar = 250)
# clean up the snippets
snippetData <- snippets_clean(snippetData)

# randomly sample three snippets
set.seed(10)
testData <- snippetData[sample(1:nrow(snippetData), 5), ]

# generate pairs for a minimum spanning tree
(snippetPairsMST <- pairs_regular_make(testData))
```

We can also use the package function to generate "gold" questions based on readability differences:

```{r}
# make a lot of candidate pairs
snippetPairsAll <- pairs_regular_make(snippetData[sample(1:nrow(snippetData), 1000), ])
# make 10 gold from these
pairs_gold_make(snippetPairsAll, n.pairs = 10)
```
   
    

    

